{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7f47df8-e05e-46b7-a1ee-3be4e76d61fd",
   "metadata": {},
   "source": [
    "# Pre-Processing Method\n",
    "This method loads in two object detection models and runs them on video data. First the videos are split into frames at a rate of 4fps, the image quality is reduced to 800 pixels, and then they are filtered, removing frames with a greyscale less than 5, and those with an absolute difference of less than 2000. Additionally, at least one frame is taken every 2 seconds, and after a period of no frames being taken becuase they all have an absolute difference less than 2000, the final frame of this period is also taken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25dbea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import fnmatch\n",
    "import csv\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import concurrent.futures\n",
    "from multiprocessing import Manager\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72933a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd Brands-YOLO8-Model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_model = YOLO('runs/detect/train/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c7718-0b59-4e0d-9d7a-cefd9f0ac679",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd '~'\n",
    "%cd 'Desktop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce9cedb-3ceb-4fe3-9a7f-3c64abc568df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Alcohol-YOLO8-Model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f900f687-08ef-4cd2-b963-a9300e99bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "alc_model = YOLO('runs/detect/ALCOHOL_100/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f13042",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9893e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output file names\n",
    "ALC_outputFilename = \"Desktop/Frames/Output-Alc.csv\" \n",
    "if os.path.exists(ALC_outputFilename):\n",
    "    print(f\"Predictions file already exists in the \\'{ALC_outputFilename}\\'.\")\n",
    "    print(f\"Please delete the existing {ALC_outputFilename} to rerun the code.\")\n",
    "\n",
    "BRANDS_outputFilename = \"Desktop/Frames/Output-Brands.csv\" \n",
    "if os.path.exists(BRANDS_outputFilename):\n",
    "    print(f\"Predictions file already exists in the \\'{BRANDS_outputFilename}\\'.\")\n",
    "    print(f\"Please delete the existing {BRANDS_outputFilename} to rerun the code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e89605-6ff3-4d03-bb79-9db918fbd25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the absolute difference between two frames\n",
    "def frames_equal(frame1, frame2):\n",
    "    gray_frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    diff = cv2.absdiff(gray_frame1, gray_frame2)\n",
    "    _, diff_threshold = cv2.threshold(diff, 50, 255, cv2.THRESH_BINARY)\n",
    "    diff_count = cv2.countNonZero(diff_threshold)\n",
    "    \n",
    "    return diff_count < 2000\n",
    "\n",
    "#check the greyscale intesity of a frame\n",
    "def overall_grayscale_intensity(frame):\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    intensity = cv2.mean(gray_frame)[0]\n",
    "    \n",
    "    return intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b7afc-4794-413e-abbf-b3d4b82a1824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperates individual predictions and retrievals all relevant information for post-processing\n",
    "def process_results(results):\n",
    "    ret = []\n",
    "    conf = results[0].boxes.conf\n",
    "    conf = conf.detach().cpu().numpy().tolist()\n",
    "    for r in results:\n",
    "        res = []\n",
    "        nums = r.boxes.cls.numpy()\n",
    "        names = r.names\n",
    "        for i in nums:\n",
    "            res.append(names[i])\n",
    "        print(res)\n",
    "    if not res:\n",
    "        return 0\n",
    "    else: \n",
    "        locations = results[0].boxes.xywh\n",
    "        locations = locations.detach().cpu().numpy().tolist()\n",
    "        locations = [':'.join(f'{round(num, 2)}' for num in sublist) for sublist in locations]\n",
    "        for i in range(len(res)):\n",
    "            ret.append([conf[i], res[i], locations[i]])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad5e856-fccd-4a50-95b6-e30422303699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path):\n",
    "    alc_rows = []\n",
    "    brands_rows = []\n",
    "    video_capture = cv2.VideoCapture(video_path) #load the video\n",
    "    \n",
    "    fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT)) #count the total frames\n",
    "    \n",
    "    frame_counter = 0\n",
    "    prev_frame = None  \n",
    "    last_counter = 0\n",
    "    last=True\n",
    "    \n",
    "    while frame_counter < total_frames: #iterate through the frames\n",
    "        frame_pos = int(frame_counter)\n",
    "        video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_pos) #extract frame at each time point\n",
    "\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        if ret:\n",
    "            height, width = frame.shape[:2]\n",
    "            if width > height: #resize the frame\n",
    "                scale_factor = 800 / width\n",
    "            else:\n",
    "                scale_factor = 800 / height\n",
    "            new_width = int(width * scale_factor)\n",
    "            new_height = int(height * scale_factor)\n",
    "            frame = cv2.resize(frame, (new_width, new_height))\n",
    "\n",
    "        if not ret: #break if there is no frame\n",
    "            break\n",
    "\n",
    "        if prev_frame is None or not frames_equal(frame, prev_frame) or last_counter>=7: #filters out unessessary frames - keeps the first frame, different frames, and at least one frame every 2 seconds\n",
    "            if last_counter>=7 and not frames_equal(frame, prev_frame): \n",
    "                last = False\n",
    "            else: \n",
    "                if last_counter>=7: last = True\n",
    "            items = [frame] if last else [frame, prev_frame] \n",
    "            timestamp = [frame_counter/fps] if last else [frame_counter/fps, (frame_counter-(fps/4))/fps]\n",
    "            for item, ts in zip(items, timestamp):\n",
    "                if overall_grayscale_intensity(item) > 5: #check greyscale\n",
    "                    minutes, seconds = divmod(ts, 60)\n",
    "                    hours, minutes = divmod(minutes, 60)\n",
    "                    time_str = f\"{int(hours):02d}_{int(minutes):02d}_{seconds:05.2f}\"\n",
    "                    output_frame_path = f\"{os.path.splitext(os.path.basename(video_path))[0]}_{time_str}.jpg\"\n",
    "\n",
    "                    with concurrent.futures.ProcessPoolExecutor(max_workers=2) as executor: #predict each model in parrallel\n",
    "                        alc_future = executor.submit(process_results, alc_model([item], conf=0.2))\n",
    "                        brands_future = executor.submit(process_results, brands_model([item], conf=0.2))\n",
    "\n",
    "                        proc_alc = alc_future.result()\n",
    "                        proc_brands = brands_future.result()\n",
    "                    \n",
    "                    video_path_parts = video_path.split('/')\n",
    "\n",
    "                        # add the results to a dataframe\n",
    "                    if proc_alc == 0:\n",
    "                        print(f\"Nothing Here: {output_frame_path}\")\n",
    "                    else: \n",
    "                        for i in range(len(proc_alc)):\n",
    "                            alc_rows.append(f\"\\n{video_path_parts[1]}, {video_path_parts[2]}, {video_path_parts[3].replace(\",\", \"\").replace(\" \", \"_\")}, {video_path_parts[4]},{time_str},{proc_alc[i][0]}, {proc_alc[i][1]}, {proc_alc[i][2]}\")\n",
    "                        print(f\"Frame saved: {output_frame_path}\")\n",
    "\n",
    "                    if proc_brands == 0:\n",
    "                        print(f\"Nothing Here: {output_frame_path}\")\n",
    "                    else: \n",
    "                        for i in range(len(proc_brands)):\n",
    "                            brands_rows.append(f\"\\n{video_path_parts[1]}, {video_path_parts[2]}, {video_path_parts[3].replace(\",\", \"\").replace(\" \", \"_\")}, {video_path_parts[4]},{time_str},{proc_brands[i][0]}, {proc_brands[i][1]}, {proc_brands[i][2]}\")\n",
    "                        print(f\"Frame saved: {output_frame_path}\")\n",
    "                \n",
    "                last_counter=0\n",
    "                last=True\n",
    "            \n",
    "        else:\n",
    "            last_counter = last_counter+1\n",
    "            last=False\n",
    "        prev_frame = frame\n",
    "\n",
    "        frame_counter += fps / 4 # 4fps\n",
    "    \n",
    "    video_capture.release()\n",
    "    print(f\"Frames extraction complete for video {video_path}\")\n",
    "    return alc_rows, brands_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a94bd",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_video(args): # for each video, call the extract_frame method\n",
    "    video_path, alc_tmp_file, brands_tmp_file = args\n",
    "    alc_dataframe, brands_dataframe = extract_frames(video_path)\n",
    "    \n",
    "    cleaned_alc_rows = [row.strip() for row in alc_dataframe]\n",
    "    cleaned_brands_rows = [row.strip() for row in brands_dataframe]\n",
    "\n",
    "        #append the results for a video to the appropriate file\n",
    "    if cleaned_alc_rows:\n",
    "        with open(alc_tmp_file, mode=\"a\") as alc_file:\n",
    "            alc_file.write(\"\\n\".join(cleaned_alc_rows) + \"\\n\")\n",
    "\n",
    "    if cleaned_brands_rows:\n",
    "        with open(brands_tmp_file, mode=\"a\") as brands_file:\n",
    "            brands_file.write(\"\\n\".join(cleaned_brands_rows) + \"\\n\")\n",
    "\n",
    "def extract_videos_from_folder(folder_path, ALC_outputFilename, BRANDS_outputFilename):\n",
    "    first_videos = []\n",
    "    for root, dirs, files in os.walk(folder_path): #extract only one video from each end file\n",
    "        for filename in files:\n",
    "            if fnmatch.fnmatch(filename, '*.mp4'):\n",
    "                if \"_avo_\" not in filename:\n",
    "                    name = os.path.join(root, filename)\n",
    "                    if 'analytics' not in name.lower() and 'digital' not in name.lower(): #dont include any analytical videos\n",
    "                        first_videos.append(name)\n",
    "                    break\n",
    "    print(len(first_videos))\n",
    "    if not first_videos:\n",
    "        print(\"No .mp4 files found in any end folder.\")\n",
    "        return\n",
    "\n",
    "        # create output files\n",
    "    with open(ALC_outputFilename, mode=\"w\") as alc_file:\n",
    "        alc_file.write(\"Student,Device,DateTime,VideoFile,Timestamp,Confidence,Prediction,Location\\n\")\n",
    "\n",
    "    with open(BRANDS_outputFilename, mode=\"w\") as brands_file:\n",
    "        brands_file.write(\"Student,Device,DateTime,VideoFile,Timestamp,Confidence,Prediction,Location\\n\")\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=15) as executor: #process the videos in parrallel\n",
    "        executor.map(process_video, [(video, output_path, ALC_outputFilename, BRANDS_outputFilename) for video in first_videos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b3562-abbd-4702-b25e-505c00d84815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder_path = \"STUDENT_DATA/\"\n",
    "extract_videos_from_folder(folder_path, ALC_outputFilename, BRANDS_outputFilename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detr_env",
   "language": "python",
   "name": "detr_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
