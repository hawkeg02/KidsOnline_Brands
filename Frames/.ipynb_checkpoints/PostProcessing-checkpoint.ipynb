{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bcce68b-1757-4d89-ac39-fe2916f1d38b",
   "metadata": {},
   "source": [
    "# PostProcessing Method\n",
    "This method reads in a csv table called Output which includes has the following information Student, Device, DateTime, VideoFile, Timestamp, Confidence, Prediction and Location. Each row in this file is its own seperate prediction. This method creates prediction intervals based on their location, timestamp and prediction type. The output of this method includes; Sudent, Device, start_time, end_time, prediction. avg_confidence, Date and Time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5ca160f-b936-4aa6-8afc-94d993329e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from shapely.geometry import box\n",
    "import torchvision\n",
    "import torch\n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f86ae637-47d5-4d34-9623-0dcc9598b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Output-Alc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31234bc3-ac0b-4452-af4d-e26899dea9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recongising the location\n",
    "def parse_location(loc):\n",
    "    return np.array(list(map(float, loc.split(':'))))\n",
    "\n",
    "#converting timestamp\n",
    "def timestamp_to_seconds(ts):\n",
    "    hours, minutes, seconds = ts.split('_')\n",
    "    total_seconds = int(hours) * 3600 + int(minutes) * 60 + float(seconds)\n",
    "    return total_seconds\n",
    "\n",
    "#finds the last item added to an interval\n",
    "def find_second_to_last(arr, target):\n",
    "    indices = [i for i, value in enumerate(arr) if value == target]\n",
    "    if len(indices) >= 2:\n",
    "        return indices[-2]\n",
    "    return None\n",
    "\n",
    "#Calculates Bouding Box Overlap\n",
    "def calculate_overlap(box1, box2):\n",
    "    x1_1, y1_1, x2_1, y2_1 = box1[0], box1[1], box1[0] + box1[2], box1[1] + box1[3]\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2[0], box2[1], box2[0] + box2[2], box2[1] + box2[3]\n",
    "\n",
    "    x1_inter = max(x1_1, x1_2)\n",
    "    y1_inter = max(y1_1, y1_2)\n",
    "    x2_inter = min(x2_1, x2_2)\n",
    "    y2_inter = min(y2_1, y2_2)\n",
    "\n",
    "    inter_width = max(0, x2_inter - x1_inter)\n",
    "    inter_height = max(0, y2_inter - y1_inter)\n",
    "    overlap_area = inter_width * inter_height\n",
    "\n",
    "    return overlap_area\n",
    "\n",
    "#Calculates Distance between bouding boxes\n",
    "def euclidean_distance_cxcywh(box1, box2):\n",
    "    cx1, cy1, _, _ = box1\n",
    "    cx2, cy2, _, _ = box2\n",
    "    distance = math.sqrt((cx1 - cx2) ** 2 + (cy1 - cy2) ** 2)\n",
    "    return distance\n",
    "\n",
    "#Filters based on bouding box overlap\n",
    "def filter(df):\n",
    "    df = df.sort_values(by=['VideoFile', 'start_time']).reset_index(drop=True)\n",
    "    VideoFile = df['VideoFile'].iloc[0]\n",
    "    End_Time = df['end_time'].iloc[0]\n",
    "    filtered_rows = []\n",
    "    temp_rows = []\n",
    "    New = True\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if df['VideoFile'].iloc[i] != VideoFile: #if they are the same video\n",
    "            VideoFile = df['VideoFile'].iloc[i]\n",
    "            End_Time = df['end_time'].iloc[i]\n",
    "            New = True\n",
    "        if temp_rows:\n",
    "            End_Time = max(df['end_time'].iloc[temp_rows])\n",
    "        if New or df['start_time'].iloc[i] > End_Time: #if don't they have overalapping intervals\n",
    "            if temp_rows:\n",
    "                filtered_rows.extend(temp_rows)\n",
    "                temp_rows = []\n",
    "            End_Time = df['end_time'].iloc[i]\n",
    "            temp_rows.append(i)\n",
    "        else: #if they do have overalapping invtervals\n",
    "            Add = True\n",
    "            for j in temp_rows:\n",
    "                if df['start_time'].iloc[i] < df['end_time'].iloc[j]:\n",
    "                    l_i = torchvision.ops.box_convert(torch.tensor(df['avg_location'].iloc[i]), in_fmt = \"cxcywh\", out_fmt = \"xywh\").numpy()\n",
    "                    l_j = torchvision.ops.box_convert(torch.tensor(df['avg_location'].iloc[j]), in_fmt = \"cxcywh\", out_fmt = \"xywh\").numpy()\n",
    "                    if calculate_overlap(l_i, l_j) > 100:\n",
    "                        base_i = df.loc[i, 'prediction'].split('-', 1)[0]\n",
    "                        base_j = df.loc[j, 'prediction'].split('-', 1)[0]\n",
    "                        if base_i == base_j: #if the brand is the same then merge the intervals\n",
    "                            df.loc[j, 'start_time'] = min(df.loc[i, 'start_time'], df.loc[j, 'start_time'])\n",
    "                            df.loc[j, 'end_time'] = max(df.loc[i, 'end_time'], df.loc[j, 'end_time'])\n",
    "                            df.loc[j, 'avg_confidence'] = max(df.loc[i, 'avg_confidence'], df.loc[j, 'avg_confidence'])\n",
    "                            df.loc[j, 'frame_count'] = df.loc[i, 'frame_count'] + df.loc[j, 'frame_count']\n",
    "                            df.loc[j, 'prediction'] = base_i\n",
    "                            Add = False\n",
    "                        else:\n",
    "                            if df['avg_confidence'].iloc[i] > df['avg_confidence'].iloc[j]:\n",
    "                                temp_rows.remove(j)\n",
    "                                temp_rows.append(i)\n",
    "                                Add = False\n",
    "                            else:\n",
    "                                Add = False\n",
    "            if Add == True:\n",
    "                temp_rows.append(i) #only one of the intervals is added - the one with the higher confidence or the merged interval\n",
    "        New=False\n",
    "        if i == len(df)-1:\n",
    "            filtered_rows.extend(temp_rows)\n",
    "    return df.iloc[filtered_rows]\n",
    "\n",
    "#Reformats the datetime column\n",
    "def split_datetime(s):\n",
    "    parts = s.split(\"_\")\n",
    "    date_str = f\"{parts[0]} {parts[1]} {parts[2]}\".strip()\n",
    "    date = datetime.strptime(date_str, \"%b %d %Y\").strftime(\"%m/%d/%Y\")\n",
    "    time_str = f\"{parts[3][:2]}:{parts[3][2:]} {parts[4]}\"  # Time in 12-hour format\n",
    "    time_24hr = datetime.strptime(time_str, \"%I:%M %p\").strftime(\"%H:%M\")\n",
    "    return pd.Series([date, time_24hr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d731d03-ceaf-4246-88be-e187368fb32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp_seconds'] = df['Timestamp'].apply(timestamp_to_seconds)\n",
    "df['location_coords'] = df['Location'].apply(parse_location)\n",
    "df = df.sort_values(by=['VideoFile', 'timestamp_seconds']).reset_index(drop=True)\n",
    "\n",
    "final_ids = {}\n",
    "unique_ids = {}\n",
    "temp_ids = {}\n",
    "result = []\n",
    "previous_time = None\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    pred = row['Prediction']\n",
    "    ts = row['timestamp_seconds']\n",
    "    loc = row['location_coords']\n",
    "    vf = row['VideoFile']\n",
    "    if ts != previous_time:\n",
    "        final_ids.update(temp_ids)\n",
    "        temp_ids={}\n",
    "    \n",
    "    # Find all the predictions with the same name within 2 seconds\n",
    "    candidates = [\n",
    "    (uid, info) for uid, info in final_ids.items() \n",
    "        if info['Prediction'] == pred and abs(info['timestamp_seconds'] - ts) <= 2 and info['VideoFile'] == vf\n",
    "    ]\n",
    "    if candidates:\n",
    "        distances = [\n",
    "            (\n",
    "                uid, \n",
    "                np.linalg.norm(info['location_coords'] - loc) + 10 * (abs(info['timestamp_seconds'] - ts) // 0.25)\n",
    "            )\n",
    "            for uid, info in candidates\n",
    "        ]\n",
    "        closest_uid, closest_dist = min(distances, key=lambda x: x[1]) #Finds the closest prediction\n",
    "        if closest_dist < 5000:  # Checks the bouding box is wihtin a certain distance\n",
    "            row_numbers = [index for index, info in enumerate(unique_ids.values()) if info['timestamp_seconds'] == ts and info['unique_id'] == closest_uid] # is there another row with the same timestamp and prediction\n",
    "            if row_numbers: #if there is another timestamp with the same prediction and timestamp then we need to assess which is most suited for the particular interval\n",
    "                timesb = list(unique_ids.values())[row_numbers[0]]['timestamp_seconds']\n",
    "                locb = list(unique_ids.values())[row_numbers[0]]['location_coords']\n",
    "                predb = list(unique_ids.values())[row_numbers[0]]['Prediction']\n",
    "                \n",
    "                indx = find_second_to_last(result, closest_uid) # grab last item of the interval\n",
    "                if indx:\n",
    "                    tarlocx = df.loc[indx, 'location_coords']\n",
    "                    distance_a = euclidean_distance_cxcywh(loc, tarlocx) #check which frame is closer\n",
    "                    distance_b = euclidean_distance_cxcywh(locb, tarlocx)\n",
    "\n",
    "                    if distance_a < distance_b: #if the new frame is clsoer then the old frame either needs to find another interval or start its own\n",
    "                        unique_id = closest_uid\n",
    "                        locb_indx = len(result) - 1 - result[::-1].index(closest_uid)\n",
    "                        \n",
    "                        distances = [row for row in distances if row[0] != closest_uid] # finds next best interval\n",
    "                        next_best = False\n",
    "                        if distances and len(distances) < 3:\n",
    "                            closest_uid, closest_dist = min(distances, key=lambda x: x[1])\n",
    "                            row_numbers = [index for index, info in enumerate(unique_ids.values()) if info['timestamp_seconds'] == ts and info['unique_id'] == closest_uid]\n",
    "                            next_best = True\n",
    "                        if next_best == True and not row_numbers:\n",
    "                            new_id = closest_uid\n",
    "                            result[locb_indx] = new_id\n",
    "                            unique_ids[new_id] = {'timestamp_seconds': timesb, 'location_coords': locb, 'Prediction': predb, 'unique_id': new_id, 'VideoFile' : vf}\n",
    "                            final_ids[new_id] = {'timestamp_seconds': timesb, 'location_coords': locb, 'Prediction': predb, 'unique_id': new_id, 'VideoFile' : vf}\n",
    "                        else:\n",
    "                            new_id = f\"{pred}_{len(set(result)) + 1:04d}\"\n",
    "                            result[locb_indx] = new_id\n",
    "                            unique_ids[new_id] = {'timestamp_seconds': timesb, 'location_coords': locb, 'Prediction': predb, 'unique_id': new_id, 'VideoFile' : vf}\n",
    "                            final_ids[new_id] = {'timestamp_seconds': timesb, 'location_coords': locb, 'Prediction': predb, 'unique_id': new_id, 'VideoFile' : vf}\n",
    "\n",
    "                    \n",
    "                    else:\n",
    "                        distances = [row for row in distances if row[0] != closest_uid] # find next best\n",
    "                        next_best = False\n",
    "                        if distances and len(distances) < 3:\n",
    "                            closest_uid, closest_dist = min(distances, key=lambda x: x[1])\n",
    "                            row_numbers = [index for index, info in enumerate(unique_ids.values()) if info['timestamp_seconds'] == ts and info['unique_id'] == closest_uid]\n",
    "                            next_best = True\n",
    "                        if next_best == True and not row_numbers:\n",
    "                            unique_id = closest_uid\n",
    "                        else:\n",
    "                            unique_id = f\"{pred}_{len(set(result)) + 1:04d}\" \n",
    "                else: # This means the previous occurance was the first so just make a new one\n",
    "                    unique_id = f\"{pred}_{len(set(result)) + 1:04d}\"\n",
    "            else: #This one means that there are no other rows in unique_ids with the same timestamp or unique_id\n",
    "                unique_id = closest_uid\n",
    "        else: # This one means that the distance is too far (unlikley)\n",
    "            unique_id = f\"{pred}_{len(set(result)) + 1:04d}\" \n",
    "    else: #There are no previous prediction with the same name and in the last 2 seconds\n",
    "        unique_id = f\"{pred}_{len(set(result)) + 1:04d}\"\n",
    "        \n",
    "    temp_ids[unique_id] = {'timestamp_seconds': ts, 'location_coords': loc, 'Prediction': pred, 'unique_id': unique_id, 'VideoFile' : vf}\n",
    "    unique_ids[unique_id] = {'timestamp_seconds': ts, 'location_coords': loc, 'Prediction': pred, 'unique_id': unique_id, 'VideoFile' : vf}\n",
    "    previous_time = ts\n",
    "    result.append(unique_id)\n",
    "\n",
    "df['unique_id'] = result\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%H_%M_%S.%f')\n",
    "df['Time'] = df['Timestamp'].dt.strftime('%H:%M:%S.%f').str[:-3]\n",
    "df[['x1', 'y1', 'x2', 'y2']] = pd.DataFrame(df['location_coords'].tolist(), index=df.index)\n",
    "\n",
    "#Aggregate the final groups\n",
    "result = df.groupby('unique_id').agg(\n",
    "    Student=('Student', 'first'),\n",
    "    Device=('Device', 'first'),\n",
    "    DateTime=('DateTime', 'first'),\n",
    "    VideoFile=('VideoFile', 'first'),\n",
    "    start_time=('Time', 'min'),\n",
    "    end_time=('Time', 'max'),\n",
    "    prediction=('Prediction', 'first'),\n",
    "    avg_confidence=('Confidence', lambda x: round(x.mean(), 2)),\n",
    "    frame_count=('Timestamp', 'count'),\n",
    "    avg_location_x1=('x1', 'median'),\n",
    "    avg_location_y1=('y1', 'median'),\n",
    "    avg_location_x2=('x2', 'median'),\n",
    "    avg_location_y2=('y2', 'median')\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "result['avg_location'] = list(zip(result['avg_location_x1'], result['avg_location_y1'], result['avg_location_x2'], result['avg_location_y2']))\n",
    "result = result[result['frame_count'] > 1]\n",
    "result = result[result['avg_confidence'] > 0.82]\n",
    "result = result.drop(columns=['unique_id', 'avg_location_x1', 'avg_location_y1', 'avg_location_x2', 'avg_location_y2'])\n",
    "result = filter(result)\n",
    "result = result[~((result['frame_count'] < 4) & (result['avg_confidence'] <= 0.90))] \n",
    "result = result.sort_values(by=['VideoFile', 'start_time']).reset_index(drop=True)\n",
    "result[['Date', 'Time']] = result['DateTime'].apply(split_datetime)\n",
    "result = result.drop(columns=['avg_location', 'DateTime', 'VideoFile'])\n",
    "result.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad70153-0537-4056-b0de-90d3cdac3b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detr_env",
   "language": "python",
   "name": "detr_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
